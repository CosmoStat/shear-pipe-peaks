{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycs.astro.wl.mass_mapping import *\n",
    "from pycs.sparsity.sparse2d.starlet import *\n",
    "from pycs.misc.cosmostat_init import *\n",
    "from pycs.astro.wl.hos_peaks_l1 import *\n",
    "\n",
    "from sp_peaks import slics\n",
    "from sp_peaks import mapping\n",
    "from sp_peaks import summary_statistics\n",
    "from sp_peaks import plotting\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bookkeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory\n",
    "root_directory = \"/n17data/tersenov/Cov_DES_SLICS\"\n",
    "\n",
    "# Open the master text file in write mode\n",
    "master_file_path = \".././input/master_file_cov.txt\"\n",
    "with open(master_file_path, \"w\") as master_file:\n",
    "    for subdir in os.listdir(root_directory):\n",
    "        # Check if the subdirectory name matches the pattern \"LOS...\"\n",
    "        if subdir.startswith(\"LOS\") and subdir[3:].isdigit():\n",
    "            subdir_path = os.path.join(root_directory, subdir)\n",
    "            \n",
    "            # Iterate over the files in the subdirectory\n",
    "            for file_name in os.listdir(subdir_path):\n",
    "                # Check if the file name matches the desired pattern\n",
    "                if file_name.startswith(\"DES_MocksCat_SLICS_4_Bin\") and file_name.endswith(\".dat\"):\n",
    "                    file_path = os.path.join(subdir_path, file_name)\n",
    "                    master_file.write(file_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the \"master_file_cov.txt\"\n",
    "master_file_path = \".././input/master_file_cov.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file paths from the \"master_file_cov.txt\"\n",
    "with open(master_file_path, \"r\") as file:\n",
    "    file_paths = file.readlines()\n",
    "    file_paths = [path.strip() for path in file_paths]\n",
    "\n",
    "# Parse these file paths\n",
    "parsed_cov_data = slics.parse_cov_SLICS_filenames(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct 124 realisations of the survey by picking each tile from a random LOS, ensuring that each file is only included once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_numbers = np.unique(parsed_cov_data['LOS']) # List of all LOS numbers\n",
    "num_realizations = 124 # Number of realizations\n",
    "num_tiles_per_realization = 19 # Number of tiles to select for each realization\n",
    "\n",
    "num_bins = 4\n",
    "bin_number = 2\n",
    "\n",
    "# Reconstruct 124 realisations of the survey by picking each tile from a random LOS, ensuring that each file is only included once.\n",
    "collections_of_files = slics.survey_realizations_reconstruction(num_realizations, num_tiles_per_realization, bin_number, parsed_cov_data['LOS'], file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak counts datavector calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Parameters\n",
    "N_GAL = 7 \n",
    "SIZE_X_DEG = 10.\n",
    "SIZE_Y_DEG = 10.\n",
    "PIX_ARCMIN = 1.\n",
    "SHAPE_NOISE = 0.44\n",
    "NSCALES = 5\n",
    "\n",
    "# Histogram parameters\n",
    "MIN_SNR = -2\n",
    "MAX_SNR = 6\n",
    "NBINS=31\n",
    "\n",
    "NUM_REALIZATIONS = 124  # Number of realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store data vectors for each realization\n",
    "data_vectors = []\n",
    "\n",
    "# Loop over realizations\n",
    "for realization_files in collections_of_files[:3]: # Use only the first ... realizations for now\n",
    "    # Initialize an empty list to store peak counts vectors for each tile in this realization\n",
    "    peak_counts_realization = []\n",
    "\n",
    "    # Loop over files (tiles) in this realization\n",
    "    for tile_file in realization_files:\n",
    "        # Load the catalog data for this tile\n",
    "        catalog_data = slics.read_catalogue_pd(tile_file)\n",
    "\n",
    "        # Extract data from the catalog\n",
    "        ra = catalog_data['RA']\n",
    "        dec = catalog_data['Dec']\n",
    "        g1_sim = catalog_data['gamma1_sim']\n",
    "        g2_sim = catalog_data['gamma2_sim']\n",
    "\n",
    "        # Calculate peak counts for this tile\n",
    "        x, y = radec2xy(np.mean(ra), np.mean(dec), ra, dec)\n",
    "        Nx, Ny = int(SIZE_X_DEG / PIX_ARCMIN * 60), int(SIZE_Y_DEG / PIX_ARCMIN * 60)\n",
    "        galmap = bin2d(x, y, npix=(Nx,Ny))\n",
    "        mask = (galmap > 0).astype(int)\n",
    "\n",
    "        sigma_noise = np.zeros_like(galmap)\n",
    "        sigma_noise[mask != 0] = SHAPE_NOISE / np.sqrt(2 * galmap[mask != 0])\n",
    "        sigma_noise[mask == 0] = np.max(sigma_noise[mask != 0]) # set the noise to the maximum value in the map where there are galaxies        noise_map_CFIS_z05 = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1]) # generate noise map\n",
    "        noise_map_CFIS_z05 = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1]) # generate noise map\n",
    "\n",
    "        e1map, e2map = bin2d(x, y, npix=(Nx, Ny), v=(g1_sim, g2_sim)) \n",
    "\n",
    "        # Shear data class initialization\n",
    "        d = shear_data()\n",
    "        d.g1 = e1map\n",
    "        d.g2 = -e2map\n",
    "        (nx,ny) = e1map.shape\n",
    "        d.mask = mask\n",
    "        # Shear noise covariance matrix\n",
    "        Ncov = np.zeros((nx,ny))\n",
    "        Ncov[mask > 0] = 2. * sigma_noise[mask > 0]**2\n",
    "        Ncov[mask == 0] = 1e9 # set the noise to the maximum value in the map where there are galaxies\n",
    "\n",
    "        d.Ncov = Ncov\n",
    "        d.nx = nx\n",
    "        d.ny = ny  \n",
    "\n",
    "        # Mass mapping class initialization\n",
    "        M = massmap2d(name='mass')\n",
    "        M.init_massmap(d.nx,d.ny)\n",
    "        M.DEF_niter = 50\n",
    "        Inpaint = True\n",
    "        M.niter_debias = 30\n",
    "        M.Verbose = False \n",
    "\n",
    "        # KS\n",
    "        ks =  M.gamma_to_cf_kappa(e1map,-e2map) \n",
    "        ks = ks.real\n",
    "        ks_noisy = ks + noise_map_CFIS_z05\n",
    "\n",
    "        WT = starlet2d(gen2=False,l2norm=False, verb=False)\n",
    "        WT.init_starlet(nx, ny, nscale=NSCALES)\n",
    "\n",
    "        H = HOS_starlet_l1norm_peaks(WT)\n",
    "        H.set_bins(Min=MIN_SNR, Max=MAX_SNR, nbins=NBINS)\n",
    "        H.get_mono_scale_peaks(ks_noisy, sigma_noise, mask=mask)\n",
    "\n",
    "        peak_counts_single = H.Mono_Peaks_Count\n",
    "\n",
    "        # Append peak counts for this tile to the list\n",
    "        peak_counts_realization.append(peak_counts_single)\n",
    "\n",
    "    # Compute the average peak counts vector for this realization\n",
    "    average_peak_counts = np.mean(peak_counts_realization, axis=0)\n",
    "\n",
    "    # Append the average peak counts vector for this realization to the list of data vectors\n",
    "    data_vectors.append(average_peak_counts)\n",
    "\n",
    "# Convert the list of data vectors into a NumPy array\n",
    "data_vectors = np.array(data_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak counts covariance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average peak counts vector across all realizations\n",
    "mean_PC_over_realizations = np.mean(data_vectors, axis=0)\n",
    "\n",
    "# Compute the deviations of peak counts in each realization from the average vector\n",
    "deviations = data_vectors - mean_PC_over_realizations\n",
    "\n",
    "# Compute the covariance matrix\n",
    "# The covariance_matrix will be a square matrix of shape (num_bins, num_bins).\n",
    "num_realizations = data_vectors.shape[0]\n",
    "covariance_matrix = np.dot(deviations.T, deviations) / (num_realizations - 1)\n",
    "\n",
    "# # Normalize the covariance matrix to the unity of the diagonal\n",
    "# diagonal_sqrt = np.sqrt(np.diag(covariance_matrix))\n",
    "# covariance_matrix_normalized = covariance_matrix / np.outer(diagonal_sqrt, diagonal_sqrt)\n",
    "\n",
    "# Normalize the covariance matrix\n",
    "max_cov_value = np.max(covariance_matrix)\n",
    "covariance_matrix_normalized = covariance_matrix / max_cov_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(covariance_matrix_normalized, title='Covariance Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_SS_PC = np.corrcoef(covariance_matrix)\n",
    "plotting.plot_map(correlation_matrix_SS_PC, title='Correlation Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale peak counts datavector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Parameters\n",
    "N_GAL = 7 \n",
    "SIZE_X_DEG = 10.\n",
    "SIZE_Y_DEG = 10.\n",
    "PIX_ARCMIN = 1.\n",
    "SHAPE_NOISE = 0.44\n",
    "NSCALES = 5\n",
    "\n",
    "# Histogram parameters\n",
    "MIN_SNR = -2\n",
    "MAX_SNR = 6\n",
    "NBINS=31\n",
    "\n",
    "NUM_REALIZATIONS = 124  # Number of realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store data the Multi-Scale Peak Counts vectors for each realization\n",
    "MS_PC_data_vectors = []\n",
    "\n",
    "# Loop over realizations\n",
    "for realization_files in collections_of_files[:3]:  # Use only the first ... realizations for now\n",
    "    # Initialize an empty list to store peak counts vectors for each scale in this realization\n",
    "    peak_counts_realization = []\n",
    "\n",
    "    # Loop over files (tiles) in this realization\n",
    "    for tile_file in realization_files:\n",
    "        # Load the catalog data for this tile\n",
    "        catalog_data = slics.read_catalogue_pd(tile_file)\n",
    "\n",
    "        # Extract data from the catalog\n",
    "        ra = catalog_data['RA']\n",
    "        dec = catalog_data['Dec']\n",
    "        g1_sim = catalog_data['gamma1_sim']\n",
    "        g2_sim = catalog_data['gamma2_sim']\n",
    "\n",
    "        # Calculate peak counts for this tile\n",
    "        x, y = radec2xy(np.mean(ra), np.mean(dec), ra, dec)\n",
    "        Nx, Ny = int(SIZE_X_DEG / PIX_ARCMIN * 60), int(SIZE_Y_DEG / PIX_ARCMIN * 60)\n",
    "        galmap = bin2d(x, y, npix=(Nx,Ny))\n",
    "        mask = (galmap > 0).astype(int)\n",
    "        sigma_noise = np.zeros_like(galmap)\n",
    "        sigma_noise[mask != 0] = SHAPE_NOISE / np.sqrt(2 * galmap[mask != 0])\n",
    "        sigma_noise[mask == 0] = np.max(sigma_noise[mask != 0]) # set the noise to the maximum value in the map where there are galaxies        noise_map_CFIS_z05 = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1]) # generate noise map\n",
    "        noise_map_CFIS_z05 = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1]) # generate noise map\n",
    "        e1map, e2map = bin2d(x, y, npix=(Nx, Ny), v=(g1_sim, g2_sim)) \n",
    "\n",
    "        # Shear data class initialization\n",
    "        d = shear_data()\n",
    "        d.g1 = e1map\n",
    "        d.g2 = -e2map\n",
    "        (nx,ny) = e1map.shape\n",
    "        d.mask = mask\n",
    "        # Shear noise covariance matrix\n",
    "        Ncov = np.zeros((nx,ny))\n",
    "        Ncov[mask > 0] = 2. * sigma_noise[mask > 0]**2\n",
    "        Ncov[mask == 0] = 1e9 # set the noise to the maximum value in the map where there are galaxies\n",
    "\n",
    "        d.Ncov = Ncov\n",
    "        d.nx = nx\n",
    "        d.ny = ny  \n",
    "\n",
    "        # Mass mapping class initialization\n",
    "        M = massmap2d(name='mass')\n",
    "        M.init_massmap(d.nx,d.ny)\n",
    "        M.DEF_niter = 50\n",
    "        Inpaint = True\n",
    "        M.niter_debias = 30\n",
    "        M.Verbose = False \n",
    "\n",
    "        # KS\n",
    "        ks =  M.gamma_to_cf_kappa(e1map,-e2map) \n",
    "        ks = ks.real\n",
    "        ks_noisy = ks + noise_map_CFIS_z05\n",
    "\n",
    "        WT = starlet2d(gen2=False,l2norm=False, verb=False)\n",
    "        WT.init_starlet(nx, ny, nscale=NSCALES)\n",
    "\n",
    "        H = HOS_starlet_l1norm_peaks(WT)\n",
    "        H.set_bins(Min=MIN_SNR, Max=MAX_SNR, nbins=NBINS)\n",
    "        H.set_data(ks_noisy, SigmaMap=sigma_noise, Mask=mask)\n",
    "        H.get_wtpeaks(Mask=mask)\n",
    "        peak_counts_multi = H.Peaks_Count\n",
    "\n",
    "        # Append peak counts for this tile to the list for this realization\n",
    "        peak_counts_realization.append(peak_counts_multi)\n",
    "\n",
    "    # Compute the average peak counts vector for this realization\n",
    "    average_peak_counts = np.mean(peak_counts_realization, axis=0)\n",
    "\n",
    "    # Append the average peak counts vector for this realization to the list of data vectors\n",
    "    MS_PC_data_vectors.append(average_peak_counts)\n",
    "\n",
    "# Convert the list of data vectors into a NumPy array\n",
    "MS_PC_data_vectors = np.array(MS_PC_data_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data vectors from a file\n",
    "MS_PC_data_vectors = np.load('.././output/MS_PC_data_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectors_reshaped = MS_PC_data_vectors.reshape(10, -1)  \n",
    "\n",
    "# Compute the average peak counts vector across all realizations for multiscale peak counts\n",
    "mean_PC_over_realizations_multi = np.mean(data_vectors_reshaped, axis=0)\n",
    "\n",
    "# Compute the deviations of peak counts in each realization from the average vector\n",
    "deviations_multi = data_vectors_reshaped - mean_PC_over_realizations_multi\n",
    "\n",
    "# Compute the covariance matrix for multiscale peak counts\n",
    "num_realizations_multi, num_bins_multi = data_vectors_reshaped.shape\n",
    "covariance_matrix_multi = np.dot(deviations_multi.T, deviations_multi) / (num_realizations_multi - 1)\n",
    "\n",
    "# Normalize the covariance matrix for multiscale peak counts\n",
    "diagonal_multi = np.sqrt(np.diag(covariance_matrix_multi))\n",
    "# Add a small epsilon to the diagonal to avoid division by zero\n",
    "epsilon = 1e-10\n",
    "covariance_matrix_normalized_multi = covariance_matrix_multi / (np.outer(diagonal_multi, diagonal_multi)+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(covariance_matrix_multi, title='Covariance Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(covariance_matrix_normalized_multi, title='Covariance Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_MS_PC = np.corrcoef(covariance_matrix_multi.T)\n",
    "plotting.plot_map(correlation_matrix_MS_PC, title='Correlation Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l1-norm datavector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and Parameters\n",
    "N_GAL = 7 \n",
    "SIZE_X_DEG = 10.\n",
    "SIZE_Y_DEG = 10.\n",
    "PIX_ARCMIN = 1.\n",
    "SHAPE_NOISE = 0.44\n",
    "NSCALES = 5\n",
    "\n",
    "# Histogram parameters\n",
    "MIN_SNR = -2\n",
    "MAX_SNR = 6\n",
    "NBINS_L1 = 40\n",
    "\n",
    "NUM_REALIZATIONS = 124  # Number of realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store data vectors for the L1-norm histogram for each realization\n",
    "L1_norm_data_vectors = []\n",
    "\n",
    "# Loop over realizations\n",
    "for realization_files in collections_of_files[:10]:  # Use only the first ... realizations for now\n",
    "    # Initialize an empty list to store L1-norm histogram vectors for each scale in this realization\n",
    "    l1_norm_histogram_realization = []\n",
    "\n",
    "    # Loop over files (tiles) in this realization\n",
    "    for tile_file in realization_files:\n",
    "        # Load the catalog data for this tile\n",
    "        catalog_data = slics.read_catalogue_pd(tile_file)\n",
    "\n",
    "        # Extract data from the catalog\n",
    "        ra = catalog_data['RA']\n",
    "        dec = catalog_data['Dec']\n",
    "        g1_sim = catalog_data['gamma1_sim']\n",
    "        g2_sim = catalog_data['gamma2_sim']\n",
    "\n",
    "        # Calculate peak counts for this tile\n",
    "        x, y = radec2xy(np.mean(ra), np.mean(dec), ra, dec)\n",
    "        Nx, Ny = int(SIZE_X_DEG / PIX_ARCMIN * 60), int(SIZE_Y_DEG / PIX_ARCMIN * 60)\n",
    "        galmap = bin2d(x, y, npix=(Nx,Ny))\n",
    "        mask = (galmap > 0).astype(int)\n",
    "        sigma_noise = np.where(mask != 0, SHAPE_NOISE / np.sqrt(2 * galmap), np.max(sigma_noise[mask != 0]))\n",
    "        noise_map_CFIS_z05 = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1]) # generate noise map\n",
    "        e1map, e2map = bin2d(x, y, npix=(Nx, Ny), v=(g1_sim, g2_sim)) \n",
    "\n",
    "        # Shear data class initialization\n",
    "        d = shear_data()\n",
    "        d.g1 = e1map\n",
    "        d.g2 = -e2map\n",
    "        (nx,ny) = e1map.shape\n",
    "        d.mask = mask\n",
    "        # Shear noise covariance matrix\n",
    "        Ncov = np.zeros((nx,ny))\n",
    "        Ncov[mask > 0] = 2. * sigma_noise[mask > 0]**2\n",
    "        Ncov[mask == 0] = 1e9 # set the noise to the maximum value in the map where there are galaxies\n",
    "\n",
    "        d.Ncov = Ncov\n",
    "        d.nx = nx\n",
    "        d.ny = ny  \n",
    "\n",
    "        # Mass mapping class initialization\n",
    "        M = massmap2d(name='mass')\n",
    "        M.init_massmap(d.nx,d.ny)\n",
    "        M.DEF_niter = 50\n",
    "        Inpaint = True\n",
    "        M.niter_debias = 30\n",
    "        M.Verbose = False \n",
    "\n",
    "        # KS\n",
    "        ks =  M.gamma_to_cf_kappa(e1map,-e2map) \n",
    "        ks = ks.real\n",
    "        ks_noisy = ks + noise_map_CFIS_z05\n",
    "\n",
    "        WT = starlet2d(gen2=False,l2norm=False, verb=False)\n",
    "        WT.init_starlet(nx, ny, nscale=NSCALES)\n",
    "\n",
    "        H = HOS_starlet_l1norm_peaks(WT)\n",
    "        H.set_data(ks_noisy, SigmaMap=sigma_noise, Mask=mask)\n",
    "        H.get_wtl1(NBINS_L1*2, Mask=mask)\n",
    "        l1norm_histogram = H.l1norm\n",
    "\n",
    "        # Append the L1-norm histogram for this tile to the list for this realization\n",
    "        l1_norm_histogram_realization.append(l1norm_histogram)\n",
    "\n",
    "    # Compute the average L1-norm histogram vector for this realization\n",
    "    average_l1_norm_histogram = np.mean(l1_norm_histogram_realization, axis=0)\n",
    "\n",
    "    # Append the average L1-norm histogram vector for this realization to the list of data vectors\n",
    "    L1_norm_data_vectors.append(average_l1_norm_histogram)\n",
    "\n",
    "# Convert the list of data vectors into a NumPy array\n",
    "L1_norm_data_vectors = np.array(L1_norm_data_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data vectors from a file\n",
    "L1_norm_data_vectors = np.load('.././output/L1_norm_data_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_norm_data_vectors_reshaped = L1_norm_data_vectors.reshape(10, -1)\n",
    "\n",
    "# Compute the average L1-norm histogram vector across all realizations for the L1-norm\n",
    "mean_L1_norm_over_realizations = np.mean(L1_norm_data_vectors_reshaped, axis=0)\n",
    "\n",
    "# Compute the deviations of L1-norm histograms in each realization from the average vector\n",
    "deviations_L1_norm = L1_norm_data_vectors_reshaped - mean_L1_norm_over_realizations\n",
    "\n",
    "# Compute the covariance matrix for the L1-norm histograms\n",
    "num_realizations_L1_norm, num_bins_L1_norm = L1_norm_data_vectors_reshaped.shape\n",
    "covariance_matrix_L1_norm = np.dot(deviations_L1_norm.T, deviations_L1_norm) / (num_realizations_L1_norm - 1)\n",
    "\n",
    "# Calculate the diagonal of the covariance matrix\n",
    "diagonal_L1_norm = np.sqrt(np.diag(covariance_matrix_L1_norm))\n",
    "\n",
    "# Calculate the correlation coefficients\n",
    "correlation_matrix_L1_norm = covariance_matrix_L1_norm / np.outer(diagonal_L1_norm, diagonal_L1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(covariance_matrix_L1_norm, title='Covariance Matrix of L1-norm Histograms', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(correlation_matrix_L1_norm, title='Correlation Matrix of L1-norm Histograms', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_L1_norm = np.corrcoef(covariance_matrix_L1_norm.T)\n",
    "plotting.plot_map(correlation_matrix_L1_norm, title='Correlation Matrix of L1-norm Histograms', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_PC_data_vectors = np.load('/home/tersenov/shear-pipe-peaks/output/data_vector_SS_PC_cs.npy')\n",
    "MS_PC_data_vectors = np.load('/home/tersenov/shear-pipe-peaks/output/MS_PC_data_vectors.npy')\n",
    "l1_norm_data_vectors = np.load('/home/tersenov/shear-pipe-peaks/output/L1_norm_data_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_PC_over_realizations = np.mean(SS_PC_data_vectors, axis=0)\n",
    "deviations = SS_PC_data_vectors - mean_PC_over_realizations\n",
    "\n",
    "num_realizations, num_bins = SS_PC_data_vectors.shape\n",
    "covariance_matrix = np.dot(deviations.T, deviations) / (num_realizations - 1)\n",
    "\n",
    "# max_cov_value = np.max(covariance_matrix)\n",
    "# covariance_matrix_normalized = covariance_matrix / max_cov_value\n",
    "\n",
    "\n",
    "\n",
    "diagonal_SS_PC = np.sqrt(np.diag(covariance_matrix))\n",
    "diagonal_SS_PC[diagonal_SS_PC == 0] = 1e-10\n",
    "correlation_matrix_SS_PC = covariance_matrix / np.outer(diagonal_SS_PC, diagonal_SS_PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_PC = np.corrcoef(SS_PC_data_vectors, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(correlation_matrix_PC, title='Covariance Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(covariance_matrix_normalized, title='Covariance Matrix of Peak Counts', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_PC_data_vectors_reshaped = MS_PC_data_vectors.reshape(10, -1)\n",
    "mean_MS_PC_over_realizations = np.mean(MS_PC_data_vectors_reshaped, axis=0)\n",
    "deviations_MS_PC = MS_PC_data_vectors_reshaped - mean_MS_PC_over_realizations\n",
    "num_realizations_MS_PC, num_bins_MS_PC = MS_PC_data_vectors_reshaped.shape\n",
    "covariance_matrix_MS_PC = np.dot(deviations_MS_PC.T, deviations_MS_PC) / (num_realizations_MS_PC - 1)\n",
    "diagonal_MS_PC = np.sqrt(np.diag(covariance_matrix_MS_PC))\n",
    "diagonal_MS_PC[diagonal_MS_PC == 0] = 1e-10\n",
    "correlation_matrix_MS_PC = covariance_matrix_MS_PC / np.outer(diagonal_MS_PC, diagonal_MS_PC)\n",
    "plotting.plot_map(correlation_matrix_MS_PC, title='MS-PC', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_MS_PC = np.corrcoef(MS_PC_data_vectors_reshaped, rowvar=False)\n",
    "plotting.plot_map(correlation_matrix_MS_PC, title='MS-PC', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norm_data_vectors_reshaped = l1_norm_data_vectors.reshape(10, -1)\n",
    "mean_l1_norm_over_realizations = np.mean(l1_norm_data_vectors_reshaped, axis=0)\n",
    "deviations_l1_norm = l1_norm_data_vectors_reshaped - mean_l1_norm_over_realizations\n",
    "num_realizations_l1_norm, num_bins_l1_norm = l1_norm_data_vectors_reshaped.shape\n",
    "covariance_matrix_l1_norm = np.dot(deviations_l1_norm.T, deviations_l1_norm) / (num_realizations_l1_norm - 1)\n",
    "diagonal_l1_norm = np.sqrt(np.diag(covariance_matrix_l1_norm))\n",
    "diagonal_l1_norm[diagonal_l1_norm == 0] = 1e-10\n",
    "correlation_matrix_l1_norm = covariance_matrix_l1_norm / np.outer(diagonal_l1_norm, diagonal_l1_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(correlation_matrix_l1_norm, title='l1-norm', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_l1_norm = np.corrcoef(l1_norm_data_vectors_reshaped, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_map(correlation_matrix_l1_norm, title='l1-norm', cmap='viridis', vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
