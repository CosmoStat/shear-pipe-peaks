{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271ebda-3d51-410d-b061-083744318b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd67a1-eb48-4cec-8cc9-dedb14fff783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycs.astro.wl.mass_mapping import *\n",
    "from pycs.sparsity.sparse2d.starlet import *\n",
    "from pycs.misc.cosmostat_init import *\n",
    "from pycs.astro.wl.hos_peaks_l1 import *\n",
    "import sp_peaks\n",
    "from sp_peaks import slics\n",
    "from sp_peaks import mapping\n",
    "from sp_peaks import summary_statistics\n",
    "from sp_peaks import plotting\n",
    "from multiprocessing import Pool\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc4362-50fe-43d2-b5ee-7ca9c5008438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS AND PARAMETERS\n",
    "N_GAL = 7 \n",
    "SIZE_X_DEG = 10.\n",
    "SIZE_Y_DEG = 10.\n",
    "PIX_ARCMIN = 1.\n",
    "SHAPE_NOISE = 0.44\n",
    "NSCALES = 5\n",
    "MIN_SNR = -2\n",
    "MAX_SNR = 6\n",
    "NBINS=31\n",
    "NBINS_L1 = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ede08-de11-49b5-9562-25945d76b242",
   "metadata": {},
   "source": [
    "# Process Tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276248db-dced-482d-9e82-232e9da667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shear_map(CATALOG_FILE, add_noise=True):\n",
    "    catalog_data = slics.read_catalogue_pd(CATALOG_FILE)\n",
    "    ra = catalog_data['RA']\n",
    "    dec = catalog_data['Dec']\n",
    "    g1_sim = catalog_data['gamma1_sim']\n",
    "    g2_sim = catalog_data['gamma2_sim']\n",
    "    \n",
    "    x, y = radec2xy(np.mean(ra), np.mean(dec), ra, dec)\n",
    "    Nx, Ny = int(SIZE_X_DEG / PIX_ARCMIN * 60), int(SIZE_Y_DEG / PIX_ARCMIN * 60)\n",
    "    galmap = bin2d(x, y, npix=(Nx, Ny))\n",
    "    mask = (galmap > 0).astype(int)\n",
    "\n",
    "    sigma_noise = np.zeros_like(galmap)\n",
    "    sigma_noise[mask != 0] = SHAPE_NOISE / np.sqrt(2 * galmap[mask != 0])\n",
    "    sigma_noise[mask == 0] = np.max(sigma_noise[mask != 0])\n",
    "    # noise_map = sigma_noise * np.random.randn(sigma_noise.shape[0], sigma_noise.shape[1])\n",
    "\n",
    "    e1map, e2map = bin2d(x, y, npix=(Nx, Ny), v=(g1_sim, g2_sim))\n",
    "\n",
    "    if add_noise:\n",
    "        # Add noise only if requested\n",
    "        noise_e1 = np.random.randn(*e1map.shape) * sigma_noise\n",
    "        noise_e2 = np.random.randn(*e2map.shape) * sigma_noise\n",
    "        e1map_noisy = e1map + noise_e1 * mask\n",
    "        e2map_noisy = e2map + noise_e2 * mask\n",
    "        return e1map_noisy, e2map_noisy, mask, sigma_noise\n",
    "    else:\n",
    "        # Return the maps without added noise\n",
    "        return e1map, e2map, mask, sigma_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5a66e-84df-41a7-b995-159b2775c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mass_map(e1map, e2map, mask, sigma_noise, method='ks'):\n",
    "    d = shear_data()\n",
    "    d.g1 = e1map\n",
    "    d.g2 = -e2map\n",
    "    (nx, ny) = e1map.shape\n",
    "    d.mask = mask\n",
    "    Ncov = np.zeros((nx, ny))\n",
    "    Ncov[mask > 0] = 2. * sigma_noise[mask > 0]**2\n",
    "    Ncov[mask == 0] = 1e9\n",
    "    d.Ncov = Ncov\n",
    "    d.nx = nx\n",
    "    d.ny = ny\n",
    "\n",
    "    if method == 'ks':\n",
    "        M = massmap2d(name='mass')\n",
    "        M.init_massmap(d.nx, d.ny)\n",
    "        M.DEF_niter = 50\n",
    "        M.niter_debias = 30\n",
    "        M.Verbose = False\n",
    "        ks = M.gamma_to_cf_kappa(e1map, -e2map)\n",
    "        ks = ks.real\n",
    "        return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18620608-0c86-4bb1-be7b-48fc40c0ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics(ks_noisy, sigma_noise, mask, nscales=NSCALES, min_snr=MIN_SNR, max_snr=MAX_SNR, nbins=NBINS, nbins_l1=NBINS_L1):\n",
    "    nx, ny = ks_noisy.shape\n",
    "    WT = starlet2d(gen2=False, l2norm=False, verb=False)\n",
    "    WT.init_starlet(nx, ny, nscale=nscales)\n",
    "    H = HOS_starlet_l1norm_peaks(WT)\n",
    "    H.set_bins(Min=min_snr, Max=max_snr, nbins=nbins)\n",
    "    H.set_data(ks_noisy, SigmaMap=sigma_noise, Mask=mask)\n",
    "    H.get_mono_scale_peaks(ks_noisy, sigma_noise, mask=mask)\n",
    "    H.get_wtpeaks(Mask=mask)\n",
    "    pc = H.Peaks_Count\n",
    "    H.get_wtl1(nbins_l1*2, Mask=mask, min_snr=-6, max_snr=6)\n",
    "\n",
    "    H.plot_mono_peaks_histogram()\n",
    "    H.plot_peaks_histo(log_scale=True)\n",
    "    H.plot_l1norm()\n",
    "    \n",
    "    return H.Mono_Peaks_Count, H.Peaks_Count, H.l1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bace91-877d-4154-b9b6-f460052e9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tile(filename, mass_mapping_method='ks', add_noise=False, save_mass_map=False, mass_map_output_file=None):\n",
    "    e1map, e2map, mask, sigma_noise = make_shear_map(filename, add_noise=add_noise)\n",
    "    ks = make_mass_map(e1map, e2map, mask, sigma_noise, method=mass_mapping_method)\n",
    "    ks_noisy = ks\n",
    "    peaks_mono, peaks_multi, l1norm = summary_statistics(ks_noisy, sigma_noise, mask)\n",
    "\n",
    "    if save_mass_map:\n",
    "        np.save(mass_map_output_file, ks*mask)\n",
    "\n",
    "    return peaks_mono, peaks_multi, l1norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9e52-126f-4beb-ae67-5caa0a2da742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage\n",
    "filename = \"/n17data/tersenov/SLICS/Cosmo_DES/16_a/LOS4/DES_MocksCat_16_a_4_Bin3_LOS4_R4.dat\"\n",
    "mass_mapping_method = \"ks\"\n",
    "save_mass_map = False\n",
    "mass_map_output_file = None\n",
    "peaks_mono, peaks_multi, l1norm = process_tile(filename, mass_mapping_method, add_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4698f95-ea01-4eb7-87b0-a7b06dc0781f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b3c8bc-2660-4cc4-aa25-d0ec0210a927",
   "metadata": {},
   "source": [
    "# Create lists of 19 tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff3a53-da24-4738-b387-243d5a6a7807",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_grouped_lists_corrected(master_file_path, output_directory):\n",
    "    \"\"\"\n",
    "    Correctly creates and saves lists of filenames for each unique combination\n",
    "    of cosmology, seed, LOS, and bin, ensuring each file has only 19 paths.\n",
    "    \n",
    "    Args:\n",
    "        master_file_path (str): Path to the master file containing all filenames.\n",
    "        output_directory (str): Directory where the lists will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Initialize a dictionary for grouping filenames\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    with open(master_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            \n",
    "            # Extract the filename and split into components\n",
    "            parts = line.split('/')\n",
    "            filename = parts[-1]\n",
    "            file_parts = filename.split('_')\n",
    "            \n",
    "            # Extract cosmology, seed, LOS, and bin information correctly\n",
    "            cosmology = parts[-3]\n",
    "            seed = cosmology.split('_')[-1]\n",
    "            LOS = parts[-2]\n",
    "            bin_part = file_parts[5]  # Assuming \"BinX\" is the 7th element\n",
    "            \n",
    "            # Construct a unique key for grouping\n",
    "            key = (cosmology, seed, LOS, bin_part)\n",
    "            groups[key].append(line)\n",
    "    \n",
    "    # Save each group of filenames to a separate file\n",
    "    for (cosmology, seed, LOS, bin_part), filenames in groups.items():\n",
    "        # Naming the output file to reflect the group's unique combination\n",
    "        output_file_name = f\"{cosmology}_{LOS}_{bin_part}.txt\"\n",
    "        output_file_path = os.path.join(output_directory, output_file_name)\n",
    "        with open(output_file_path, 'w') as output_file:\n",
    "            for filename in filenames:\n",
    "                output_file.write(filename + \"\\n\")\n",
    "\n",
    "master_file_path = \".././input/master_file.txt\"\n",
    "output_directory = \".././output/tiles_lists/\"\n",
    "create_grouped_lists_corrected(master_file_path, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5b1b1-0bf5-45f8-960a-d95fdbb2367f",
   "metadata": {},
   "source": [
    "# Process footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba836f8-6599-4fe4-ac48-01e94c8f45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(args):\n",
    "    filename, mass_mapping_method, add_noise, save_mass_map = args\n",
    "    \n",
    "    # Construct output filename for the mass map\n",
    "    base_name, file_ext = os.path.splitext(filename)\n",
    "    new_file_ext = '.npy'\n",
    "    mass_map_output_file = f\"{base_name}_{mass_mapping_method}{new_file_ext}\" if save_mass_map else None\n",
    "    \n",
    "    # Simulate processing the tile\n",
    "    summary_statistics = process_tile(filename, mass_mapping_method, add_noise, save_mass_map, mass_map_output_file)\n",
    "    return summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98629e5-95ca-4d8e-bcef-543d7d386fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_footprint(file_list_path, output_dir=None, mass_mapping_method='ks', add_noise=True, save_mass_map=False, num_processes=19):\n",
    "    \"\"\"\n",
    "    Processes a footprint by parallelizing over the number of tiles in a footprint\n",
    "    and returns a single averaged vector for each summary statistic across all tiles.\n",
    "    \"\"\"\n",
    "    if save_mass_map and output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(file_list_path, 'r') as file:\n",
    "        filenames = file.read().splitlines()\n",
    "    \n",
    "    args = [(filename, mass_mapping_method, add_noise, save_mass_map) for filename in filenames]\n",
    "    \n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(worker, args)\n",
    "    \n",
    "    # Initialize lists to hold each type of summary statistic separately\n",
    "    SS_PC_data = []\n",
    "    MS_PC_data = []\n",
    "    l1_norm_data = []\n",
    "    \n",
    "    # Iterate over the results to collect the statistics\n",
    "    for SS_PC, MS_PC, l1_norm in results:\n",
    "        SS_PC_data.append(SS_PC)\n",
    "        MS_PC_data.append(MS_PC)\n",
    "        l1_norm_data.append(l1_norm)\n",
    "    \n",
    "    # Calculate the mean of each summary statistic across all tiles\n",
    "    SS_PC_mean = np.mean(SS_PC_data, axis=0)\n",
    "    MS_PC_mean = np.mean(MS_PC_data, axis=0)\n",
    "    l1_norm_mean = np.mean(l1_norm_data, axis=0)\n",
    "    \n",
    "    # Return the averaged statistics\n",
    "    return SS_PC_mean, MS_PC_mean, l1_norm_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c203f9-1cb7-4c55-b11f-e54327f5ecb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_list_path = \".././output/tiles_lists/19_f_LOS2_Bin3.txt\" \n",
    "output_directory = '/n17data/tersenov/SLICS/Cosmo_DES/mass_maps'\n",
    "\n",
    "# Call process_footprint with your parameters\n",
    "SS_PC_mean, MS_PC_mean, l1_norm_mean = process_footprint(\n",
    "    file_list_path,\n",
    "    output_directory,\n",
    "    mass_mapping_method='ks', \n",
    "    save_mass_map=True,\n",
    "    num_processes=19\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98517d6-520c-464a-8225-724ef9d5c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-6, 6, 81)\n",
    "binscenter = 0.5 * (bins[:-1] + bins[1:])\n",
    "plt.plot(binscenter, l1_norm_mean[0])\n",
    "plt.plot(binscenter, l1_norm_mean[1])\n",
    "plt.plot(binscenter, l1_norm_mean[2])\n",
    "plt.plot(binscenter, l1_norm_mean[3])\n",
    "plt.plot(binscenter, l1_norm_mean[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc3efd-0a16-4098-96f4-a9d163507f53",
   "metadata": {},
   "source": [
    "# Process Cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cba132-d89f-4c0d-8a14-0f5a264aa4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cosmo(cosmology, cosmo_dir, output_dir, mass_mapping_method='ks', add_noise=True, save_mass_map=False, num_processes=19):\n",
    "    \"\"\"\n",
    "    Processes files for a specific cosmology and bin by parallelizing over the tiles in a footprint\n",
    "    and saves a 10-row table (2 seeds x 5 LOS) for each bin.\n",
    "    \"\"\"\n",
    "    if save_mass_map and output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define bins, seeds, and LOS based on your setup\n",
    "    bins = ['Bin1', 'Bin2', 'Bin3', 'Bin4']\n",
    "    seeds = ['a', 'f']  # Example seeds\n",
    "    LOS_range = range(1, 6)  # Example LOS 1 through 5\n",
    "    \n",
    "    for bin in bins:\n",
    "        all_results = []  # Reset for each bin\n",
    "        \n",
    "        for seed in seeds:\n",
    "            for LOS in LOS_range:\n",
    "                # Find the specific file for each combination of cosmology, bin, seed, LOS\n",
    "                file_name_pattern = f\"{cosmology}_{seed}_LOS{LOS}_{bin}.txt\"\n",
    "                file_list_path = glob(os.path.join(cosmo_dir, file_name_pattern))\n",
    "                \n",
    "                # Skip if no file matches the pattern\n",
    "                if not file_list_path:\n",
    "                    print(f\"File not found for pattern: {file_name_pattern}\")\n",
    "                    continue\n",
    "                \n",
    "                # Assuming only one file matches, use the first one found\n",
    "                SS_PC_mean, MS_PC_mean, l1_norm_mean = process_footprint(\n",
    "                    file_list_path[0],\n",
    "                    output_dir,\n",
    "                    mass_mapping_method,\n",
    "                    add_noise,\n",
    "                    save_mass_map,\n",
    "                    num_processes\n",
    "                )\n",
    "                \n",
    "                # Append the results with full vectors preserved\n",
    "                all_results.append((seed, LOS, SS_PC_mean, MS_PC_mean, l1_norm_mean))\n",
    "        \n",
    "        # Convert the results to a structured numpy array\n",
    "        dtype = [('seed', 'U10'), ('LOS', int),\n",
    "                 ('SS_PC_mean', np.object_), ('MS_PC_mean', np.object_), ('l1_norm_mean', np.object_)]\n",
    "        results_array = np.array(all_results, dtype=dtype)\n",
    "        \n",
    "        # Save the results array for the current bin\n",
    "        save_path = os.path.join(output_dir, f\"{cosmology}_{bin}_{mass_mapping_method}_run.npy\")\n",
    "        np.save(save_path, results_array)\n",
    "        print(f\"Saved: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca2f5c7-6b81-47a0-a763-c9a75d3e639a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "cosmology = '19'  # Specify the cosmology you're processing\n",
    "cosmo_dir = \"../output/tiles_lists/\"  # Directory containing the .txt files\n",
    "output_directory = '/n17data/tersenov/SLICS/Cosmo_DES/summary_stats'  # Directory to save the summary stats\n",
    "\n",
    "# Process the specified cosmology and save the results for each bin\n",
    "process_cosmo(\n",
    "    cosmology,\n",
    "    cosmo_dir,\n",
    "    output_directory,\n",
    "    'ks',  # Example mass mapping method\n",
    "    True,  # Add noise\n",
    "    True,  # Save mass maps\n",
    "    19  # Number of processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e1d55-da16-4761-8b04-851072086e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo19_bin1 = np.load('/n17data/tersenov/SLICS/Cosmo_DES/summary_stats/19_Bin1_ks_run.npy', allow_pickle=True)\n",
    "cosmo19_bin2 = np.load('/n17data/tersenov/SLICS/Cosmo_DES/summary_stats/19_Bin2_ks_run.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab16329-4475-4674-b309-269f24d2c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo19_bin1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebfb6e-9547-4b51-9afa-6d2d5dec0759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(-6, 6, 81)\n",
    "binscenter = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        plt.plot(binscenter, cosmo19_bin1[i][4][j])\n",
    "    plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        plt.plot(binscenter, cosmo19_bin2[i][4][j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a72ae3-285e-4347-80d9-c64c5679ea23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(-2, 6, 31)\n",
    "binscenter = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        plt.plot(binscenter, cosmo19_bin1[i][3][j])\n",
    "        plt.yscale('log')\n",
    "        plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
